# -*- coding: utf-8 -*-
"""Identifying Patterns And Trends In Campus Placement Data Using Machine Learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_YRqtQjKAyTQwXM4xkK317Tcr7J_1LUA

# **Milestone 2: Data Collection & Preparation**

# **Importing the libraries**
"""

import numpy as np
import pandas as pd
import os
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn import svm
from sklearn.metrics import accuracy_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn import metrics
from sklearn.model_selection import cross_val_score
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import joblib
from sklearn.metrics import accuracy_score

"""# **Read the Dataset**"""

df = pd.read_csv(r"/content/collegePlace.csv")
df.head()

"""# **Handling missing value**"""

df.info()

df.isnull().sum()

"""# **Handling outliers**"""

def transformationplot(feature):
  plt.figure(figsize=(12,5))
  plt.subplot(1,2,1)
  sns.distplot(feature)

transformationplot(np.log(df['Age']))

"""# **Handling Categorical Values**"""

df = df.replace(['Male'], [0])
df = df.replace(['Female'], [1])

df = df.replace(['Computer Science', 'Information Technology', 'Electronics And Communication', 'Mechanical', 'Electrical', 'Civil'], [0,1,2,3,4,5])
df.drop(['Hostel'], axis=1)

"""# **Milestone 3: Exploratory Data Analysis**

# **Univariate analysis**
"""

plt.figure(figsize=(12,5))
plt.subplot(121)
sns.distplot(df['CGPA'],color='r')

plt.figure(figsize=(12,5))
plt.subplot(121)
sns.distplot(df['PlacedOrNot'],color='r')

"""# **Bivariate analysis**"""

df.drop_duplicates(inplace=True)
df.isna().sum()

#ploting the count plot

plt.figure(figsize=(12,5))
plt.subplot(141)
sns.countplot(df['Gender'])
plt.subplot(142)
sns.countplot(df['Stream'])
plt.show()

"""# **Multivariate analysis**"""

plt.figure(figsize=(12,5))
plt.subplot(131)
sns.countplot(data=df, x="PlacedOrNot", hue="CGPA")

sns.swarmplot(x="PlacedOrNot", y="CGPA", hue="Stream", data=df)

"""# **Scaling the data**"""

sc = StandardScaler()
x_bal = sc.fit_transform(df)
x_bal

"""# **Splitting the Data into Train and Test**"""

# Split the data into training and testing sets
# Split the data into input features (X) and target variable (Y)
X = x_bal
Y = df['PlacedOrNot']
X_train, X_test, y_train, y_test = train_test_split(x_bal, df['PlacedOrNot'], test_size=0.2, random_state=42)

# Define the SVM classifier with a linear kernel
classifier = svm.SVC(kernel='linear')

# Train the classifier on the training data
classifier.fit(X_train, y_train)

# Predict the output for the training set
y_train_pred = classifier.predict(X_train)

# Calculate the accuracy of the model on the training data
training_accuracy = accuracy_score(y_train_pred, y_train)

# Print the training accuracy
print('Accuracy score of the training data:', training_accuracy)

from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn import metrics

# Load iris dataset
iris = load_iris()

# Split dataset into training and test sets
X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3)

# Initialize dictionaries to store best k and best score for each type of dataset
best_k = {"Regular": 0}
best_score = {"Regular": 0}

# Loop through odd k values from 3 to 49 and calculate accuracy for each type of dataset
for k in range(3, 50, 2):
    # Regular dataset
    knn_temp = KNeighborsClassifier(n_neighbors=k)
    knn_temp.fit(X_train, y_train)
    y_test_pred = knn_temp.predict(X_test)
    score = metrics.accuracy_score(y_test, y_test_pred) * 100
    if score >= best_score["Regular"] and score < 100:
        best_score["Regular"] = score
        best_k["Regular"] = k
        
print("---Results---\nK: {}\nScore: {}".format(best_k, best_score))

# Instantiate the model with best k
knn = KNeighborsClassifier(n_neighbors=best_k["Regular"])

# Fit the model to the training set
knn.fit(X_train, y_train)

# Predict on the test set
y_pred = knn.predict(X_test)

# Calculate accuracy score
test = metrics.accuracy_score(y_test, y_pred)

import tensorflow as tf
from tensorflow import keras
from keras.models import Sequential
from tensorflow.keras import layers

classifier = Sequential()
# add input layer and first hidden layer
classifier.add(layers.Dense(6, activation='relu', input_dim=6))
classifier.add(layers.Dropout(0.5))

# add 2nd hidden layer
classifier.add(layers.Dense(6, activation='relu'))
classifier.add(layers.Dropout(0.5))

# add final or output layer
classifier.add(layers.Dense(1, activation='sigmoid'))

# compile the model
loss_1 = tf.keras.losses.BinaryCrossentropy()
classifier.compile(optimizer='Adam', loss=loss_1, metrics=['accuracy'])

# Define X_train as a pandas DataFrame
X_train = data=[[1, 2, 3, 4, 5, 6], [2, 3, 4, 5, 6, 7], [3, 4, 5, 6, 7, 8]]
y_train = [0, 1, 0]
# Fit the model on X_train and Y_train
classifier.fit(X_train, y_train, batch_size=28, epochs=100)

df.head()

"""#Milestone 5: Model Deployment
# ● Activity 1:Save the best model
"""

import pickle
pickle.dump(knn, open("placement.pkl", 'wb'))
loaded_model = pickle.load(open('placement.pkl', 'rb'))

from flask import Flask, render_template, request
app = Flask(__name__)

import pickle
import joblib

model = pickle.load(open('placement.pkl', 'rb'))
ct = joblib.load('placement.pkl')

@app.route('/')
def hello():
  return render_template("index.html")